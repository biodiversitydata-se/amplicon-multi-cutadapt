import os

# this container defines the underlying OS for each job when using the workflow
# with --use-conda --use-singularity
singularity: "docker://continuumio/miniconda3:4.9.2"

# Set default config file
configfile: "config/config.yaml"

localrules: all

def read_samples(datadir):
    from glob import glob
    import re
    sample_re = re.compile("(.+)_R([12])_(.+).fastq.gz")
    samples = {}
    R1_files = sorted(glob(f"{datadir}/**/*R1*.fastq.gz", recursive=True))
    R2_files = sorted(glob(f"{datadir}/**/*R2*.fastq.gz", recursive=True))
    for i, f1 in enumerate(R1_files):
        f2 = R2_files[i]
        try:
            prefix, read, suffix = sample_re.search(f1).groups()
        except AttributeError:
            print(f1)
            continue
        sample = os.path.basename(prefix)
        samples[sample] = {'R1': f1, 'R2': f2}
    return samples

# Read samples from file
samples = read_samples(config["paths"]["raw_data_dir"])

rule all:
    input:
        expand("results/cutadapt/{sample}_R{i}.1st.fastq.gz",
            sample = samples.keys(), i = [1,2])

rule cutadapt1:
    input:
        R1 = lambda wildcards: samples[wildcards.sample]["R1"],
        R2 = lambda wildcards: samples[wildcards.sample]["R2"]
    output:
        "results/cutadapt/{sample}_R1.1st.fastq.gz",
        "results/cutadapt/{sample}_R2.1st.fastq.gz"
    log: "logs/cutadapt/{sample}.1st.log"
    threads: config["cutadapt"]["threads"]
    conda: "envs/cutadapt.yml"
    params:
        f=" ".join(["-a {}".format(x) for x in config["primers"]["forward"]]),
        r=" ".join(["-A {}".format(x) for x in config["primers"]["reverse"]]),
        min_len=config["cutadapt"]["minimum_length"]
    resources:
        runtime = lambda wildcards, attempt: attempt**2*30
    shell:
        """
        cutadapt -j {threads} {params.f} {params.r} -o {output[0]} \
            -p {output[1]} --minimum-length={params.min_len} \
             {input[0]} {input[1]} > {log} 2>&1
        """
